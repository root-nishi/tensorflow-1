{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery APIs\n",
    "\n",
    "Cloud Datalab provides an integrated environment for working with BigQuery for both adhoc, exploratory work as well as pipeline development. This notebook introduces some of the APIs that Cloud Datalab provides for working with BigQuery.\n",
    "\n",
    "You've already seen the use of `%%sql` in the [Hello BigQuery](Hello BigQuery.ipynb) notebook, and various `%%bigquery` commands in the [BigQuery Commands](BigQuery Commands.ipynb) notebook. These BigQuery commands are built using the same BigQuery APIs that are available for your own use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the API\n",
    "\n",
    "The Cloud Datalab APIs are provided in the `gcpdata` Python library and the BigQuery functionality is contained within the `gcp.bigquery` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gcp.bigquery as bq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Data\n",
    "\n",
    "The most important API with BigQuery is the one that allows you to execute a SQL query. The `bq.Query` class provides that functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and run a SQL query\n",
    "bq.Query('SELECT * FROM [cloud-datalab-samples:httplogs.logs_20140615] LIMIT 3').results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "In the example above, the SQL was written as a Python string literal. In Cloud Datalab, you can also specify your query as vanilla SQL. Here is the equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module logspreview\n",
    "SELECT * FROM [cloud-datalab-samples:httplogs.logs_20140615] LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a query using the SQL module defined above\n",
    "q = bq.Query(logspreview)\n",
    "\n",
    "# Run the query, with caching turned off (for sample purposes only), so we're sure to be\n",
    "# able to retrieve metadata such as bytes processed from the resulting query job.\n",
    "results = q.results(use_cache = False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results object is a `QueryResultsTable` class, and can be enumerated like a regular Python list, in addition to retrieving metadata about the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspecting the results, and the associated job\n",
    "print results.sql\n",
    "print str(results.length) + ' rows'\n",
    "print str(results.job.bytes_processed) + ' bytes processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the programmatic representation;\n",
    "# Converting the QueryResultsTable to a vanilla list enables viewing the literal data,\n",
    "# as well as side-stepping the HTML rendering seen above.\n",
    "list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling with bq.Query\n",
    "\n",
    "The `Query` class has a number of other methods such as the ability to sample against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module logs\n",
    "SELECT * FROM [cloud-datalab-samples:httplogs.logs_20140615]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use a hash-based sampling strategy that hashes the timestamp, and takes a 1% sample.\n",
    "# By default, all fields are chosen, but a particular projection can be specified as well.\n",
    "# Further limit to 10, since the only use of the sampled results is to display a table\n",
    "# in this case.\n",
    "sampling = bq.Sampling.hashed('timestamp', percent=1, count=10, fields = ['timestamp', 'latency'])\n",
    "sample = bq.Query(logs).sample(sampling = sampling)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sampling is implemented using standard SQL constructs, and is performed in BigQuery,\n",
    "# thereby limiting the results retrieved into the notebook.\n",
    "print sample.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSets and Tables\n",
    "\n",
    "In addition to executing queries, BigQuery objects like DataSets, Tables and their Schemas can be accessed programmatically as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = bq.DataSets(project_id = 'cloud-datalab-samples')\n",
    "for ds in datasets:\n",
    "  print ds.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_dataset = list(datasets)[1]\n",
    "tables = sample_dataset.tables()\n",
    "for table in tables:\n",
    "  print '%s (%d rows - %d bytes)' % (table.name.table_id, table.metadata.rows, table.metadata.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = bq.Table('cloud-datalab-samples:httplogs.logs_20140615')\n",
    "fields = map(lambda tsf: tsf.name, table.schema)\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new dataset (this will be deleted later in the notebook)\n",
    "sample_dataset = bq.DataSet('sample')\n",
    "sample_dataset.create(friendly_name = 'Sample DataSet', description = 'Created from Sample Notebook')\n",
    "sample_dataset.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To create a table, we also need to create a schema.\n",
    "# Its easiest to create a schema from some existing data, so this\n",
    "# example demonstrates using an example object\n",
    "sample_row = {\n",
    "  'name': 'string value',\n",
    "  'value': 0,\n",
    "  'flag': True\n",
    "}\n",
    "sample_schema = bq.Schema.from_data([sample_row])\n",
    "\n",
    "sample_table = bq.Table(\"sample.sample_table\").create(schema = sample_schema, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the cell below to see the contents of the new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(sample_dataset.tables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clear out sample resources\n",
    "sample_dataset.delete(delete_contents = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking Ahead\n",
    "\n",
    "This notebook covered a small subset of the APIs. Subsequent notebooks will cover additional capabilities such as importing and exporting data into and from BigQuery tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
